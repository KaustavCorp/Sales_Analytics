// Use DBML to define your database structure
// Docs: https://dbml.dbdiagram.io/docs
Project Sales_Analytics {
  database_type: 'MS SQL Server'
  Note: 'Sales_Analytics is a modular PySpark-based ELT pipeline designed to transform raw sales data into a structured, query-optimized dimensional model using the medallion architecture'
}

Table dw.DimCustomer {
    customer_id INT [primary key]
    customer_name NVARCHAR(100)
    customer_email NVARCHAR(100)
    region NVARCHAR(50)
}

Table dw.DimProduct {
    product_id INT [primary key]
    product_name NVARCHAR(100)
    category NVARCHAR(50)
    list_price DECIMAL(12,2)
}

  Table dw.DimStore {
    store_id INT [primary key]
    store_location NVARCHAR(100)
    store_manager NVARCHAR(100)
}

Table dw.DimDate {
    date_id INT [primary key]
    date DATE
    year INT
    month INT
    day INT
    month_name NVARCHAR(20)
    weekday_name NVARCHAR(20)
    quarter INT
}

Table dw.FactSales {
    orderline_id INT [primary key]
    order_id INT
    customer_id INT [ref: > dw.DimCustomer.customer_id ]
    store_id INT [ref: > dw.DimStore.store_id ]
    product_id INT [ref: > dw.DimProduct.product_id ]
    date_id INT [ref: > dw.DimDate.date_id ]
    order_date DATE
    order_status NVARCHAR(20)
    quantity INT
    unit_price DECIMAL(12,2)
    discount DECIMAL(4,2)
    gross_amount DECIMAL(18,2)
    net_amount DECIMAL(18,2)
    }